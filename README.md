# Active-Learning-in-Quantum-Classifiers



import matplotlib.pyplot as plt

# 1. Dados extraídos dos teus logs
data = {
    '(10P + 0A)': {
        'labels': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380],
        'precision': [0.6721, 0.6705, 0.6908, 0.6707, 0.6944, 0.7242, 0.7355, 0.7357, 0.7368, 0.7456, 0.7348, 0.7684, 0.7673, 0.7860, 0.7770, 0.7729, 0.7751, 0.7747, 0.7736, 0.7720, 0.7731, 0.7727, 0.7797, 0.7876, 0.7842, 0.7878, 0.7891, 0.7950, 0.7905, 0.7968, 0.7979, 0.7961, 0.7993, 0.8009]
    },
    '(9P + 1A)': {
        'labels': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 500, 510, 520, 530, 540, 550, 560, 570, 580, 590, 600, 610, 620, 630, 640, 650, 660, 670, 680],
        'precision': [0.6721, 0.6705, 0.6755, 0.6825, 0.6894, 0.6946, 0.6976, 0.7174, 0.7163, 0.7273, 0.7323, 0.7348, 0.7436, 0.7512, 0.7542, 0.7578, 0.7609, 0.7688, 0.7706, 0.7677, 0.7693, 0.7736, 0.7758, 0.7781, 0.7776, 0.7794, 0.7794, 0.7702, 0.7774, 0.7763, 0.7727, 0.7760, 0.7763, 0.7754, 0.7776, 0.7853, 0.7891, 0.7912, 0.7914, 0.7918, 0.7873, 0.7941, 0.7925, 0.7963, 0.7925, 0.7927, 0.7984, 0.7912, 0.7948, 0.7916, 0.7939, 0.7925, 0.7952, 0.7945, 0.7945, 0.7945, 0.7948, 0.7954, 0.7982, 0.7927, 0.7995, 0.7988, 0.7991, 0.8054]
    },
    '(8P + 2A)': {
        'labels': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240],
        'precision': [0.6721, 0.7172, 0.7194, 0.7276, 0.7461, 0.7548, 0.7569, 0.7544, 0.7625, 0.7634, 0.7648, 0.7677, 0.7842, 0.7869, 0.7876, 0.7943, 0.7898, 0.7907, 0.7936, 0.8011]
    },
    '(7P + 3A)': {
        'labels': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400],
        'precision': [0.6721, 0.6626, 0.6865, 0.6811, 0.6831, 0.7023, 0.7018, 0.7264, 0.7375, 0.7476, 0.7494, 0.7461, 0.7664, 0.7591, 0.7718, 0.7729, 0.7661, 0.7742, 0.7686, 0.7851, 0.7819, 0.7851, 0.7770, 0.7815, 0.7828, 0.7903, 0.7927, 0.7903, 0.7914, 0.7936, 0.7961, 0.7952, 0.7975, 0.7972, 0.7968, 0.8022]
    },
    '(6P + 4A)': {
        'labels': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220],
        'precision': [0.6721, 0.6748, 0.6816, 0.7007, 0.7104, 0.7240, 0.7382, 0.7388, 0.7533, 0.7616, 0.7704, 0.7844, 0.7833, 0.7853, 0.7916, 0.7963, 0.7950, 0.8020]
    },
    '(5P + 5A)': {
        'labels': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220],
        'precision': [0.6721, 0.6964, 0.7037, 0.7014, 0.7174, 0.7323, 0.7639, 0.7564, 0.7429, 0.7693, 0.7830, 0.7844, 0.7916, 0.7857, 0.7889, 0.7932, 0.7963, 0.8013]
    },
    '(4P + 6A)': {
        'labels': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390],
        'precision': [0.6721, 0.7124, 0.7244, 0.7172, 0.7296, 0.7368, 0.7404, 0.7542, 0.7591, 0.7576, 0.7488, 0.7424, 0.7415, 0.7528, 0.7632, 0.7625, 0.7614, 0.7684, 0.7713, 0.7711, 0.7729, 0.7781, 0.7783, 0.7844, 0.7871, 0.7945, 0.7952, 0.7991, 0.7970, 0.7984, 0.7993, 0.7948, 0.7975, 0.7950, 0.8027]
    },
    '(3P + 7A)': {
        'labels': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270],
        'precision': [0.6721, 0.6678, 0.6885, 0.6910, 0.7131, 0.7170, 0.7264, 0.7377, 0.7429, 0.7526, 0.7675, 0.7700, 0.7819, 0.7826, 0.7866, 0.7900, 0.7876, 0.7936, 0.7882, 0.7988, 0.7950, 0.7997, 0.8002]
    },
    '(2P + 8A)': {
        'labels': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220],
        'precision': [0.6721, 0.6788, 0.6901, 0.7176, 0.7262, 0.7413, 0.7485, 0.7553, 0.7560, 0.7625, 0.7621, 0.7641, 0.7677, 0.7830, 0.7954, 0.7993, 0.7882, 0.8011]
    },
    '(1P + 9A)': {
        'labels': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160],
        'precision': [0.6721, 0.6915, 0.7289, 0.7276, 0.7384, 0.7424, 0.7497, 0.7722, 0.7880, 0.7934, 0.7982, 0.8009]
    },
    '(0P + 10A)': {
        'labels': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150],
        'precision': [0.6721, 0.6809, 0.7005, 0.7109, 0.7165, 0.7280, 0.7350, 0.7535, 0.7673, 0.7790, 0.8013]
    }
}

# 2. Ordem das estratégias (para corresponder à legenda)
strategy_order = [
    '(10P + 0A)',
    '(9P + 1A)',
    '(8P + 2A)',
    '(7P + 3A)',
    '(6P + 4A)',
    '(5P + 5A)',
    '(4P + 6A)',
    '(3P + 7A)',
    '(2P + 8A)',
    '(1P + 9A)',
    '(0P + 10A)'
]

# 3. Criar o Gráfico
plt.figure(figsize=(15, 9)) # Define um bom tamanho para a figura

# 4. Plotar cada estratégia
for strategy_name in strategy_order:
    labels = data[strategy_name]['labels']
    precision = data[strategy_name]['precision']
    
    # Usar 'linestyle' e 'marker' para replicar o estilo do gráfico original
    plt.plot(labels, precision, linestyle='-', marker='.', markersize=8, label=strategy_name)

# 5. Adicionar Elementos de Estilo
# Título e Rótulos dos Eixos
plt.title('Comparison of Active + Passive Learning Strategies', fontsize=16)
plt.xlabel('Number of Labeled Samples', fontsize=12)
plt.ylabel('Precision in Test Set', fontsize=12)

# Linha da Meta (Target)
plt.axhline(y=0.8, color='black', linestyle=':', linewidth=2, label='80.0% Target')

# Grelha (Grid)
plt.grid(True, linestyle='--', alpha=0.6)

# Definir limites dos eixos (opcional, mas ajuda na visualização)
# Começa um pouco abaixo da precisão mais baixa e vai um pouco acima de 80%
plt.ylim(0.66, 0.81) 
# Começa no início e vai até ao máximo de rótulos do (9P + 1A)
plt.xlim(min(data['(10P + 0A)']['labels']) - 10, max(data['(9P + 1A)']['labels']) + 10) 

# Legenda
plt.legend(title='Strategy (Passive + Active)', loc='lower right', fontsize=10)

# 6. Mostrar o Gráfico
plt.tight_layout() # Ajusta o plot para evitar cortes
plt.show()