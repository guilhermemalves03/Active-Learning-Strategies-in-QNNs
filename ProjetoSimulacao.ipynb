{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dab83c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.primitives import Estimator\n",
    "from qiskit.circuit.library import ZFeatureMap, EfficientSU2\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit.quantum_info import SparsePauliOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c947734",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_QUBITS = 4\n",
    "N_LAYERS = 3\n",
    "TARGET_ACCURACY = 0.80\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "DIGITS_TO_CLASSIFY = [0, 1]\n",
    "N_INITIAL_SAMPLES = 20\n",
    "TOTAL_QUERY_BATCH_SIZE = 10 \n",
    "ACTIVE_BATCH_SIZE = 200     \n",
    "BATCH_SIZE_TRAIN = 10\n",
    "\n",
    "\n",
    "LEARNING_RATE = 0.01\n",
    "N_INITIAL_EPOCHS = 50       \n",
    "N_FINETUNE_EPOCHS = 2       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8523519c",
   "metadata": {},
   "source": [
    "## Now we will start the pre-processing\n",
    "Here we will load MNIST dataset, Apply PCA and then divide by the digits to classify:\n",
    "\n",
    "$$ [0,1]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd6b5fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    \n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "    y = y.astype(int)\n",
    "\n",
    "    mask = np.isin(y, DIGITS_TO_CLASSIFY)\n",
    "    X_filtered = X[mask]\n",
    "    y_filtered = y[mask]\n",
    "    y_mapped = np.where(y_filtered == DIGITS_TO_CLASSIFY[0], 0, 1)\n",
    "\n",
    "    X_scaled = X_filtered / 255.0 \n",
    "    pca = PCA(n_components=N_QUBITS)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    X_pool, X_test, y_pool, y_test = train_test_split(\n",
    "        X_pca, y_mapped, \n",
    "        test_size=0.3, random_state=RANDOM_SEED, stratify=y_mapped\n",
    "    )\n",
    "    \n",
    "    print(f\"Data processed succecfully. Pool: {len(y_pool)} samples. Test: {len(y_test)} samples.\")\n",
    "    return X_pool, y_pool, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89ac8d2",
   "metadata": {},
   "source": [
    "## Hybrid Model (QNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b834e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridQNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_qubits, n_layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        feature_map = ZFeatureMap(n_qubits)\n",
    "        ansatz = EfficientSU2(n_qubits, reps=n_layers)\n",
    "        \n",
    "        qc = QuantumCircuit(n_qubits)\n",
    "        qc.compose(feature_map, inplace=True)\n",
    "        qc.compose(ansatz, inplace=True)\n",
    "        \n",
    "        pauli_string = \"I\" * (n_qubits - 1) + \"Z\" \n",
    "        observable = SparsePauliOp(pauli_string)\n",
    "        \n",
    "        estimator = Estimator()\n",
    "\n",
    "        qnn = EstimatorQNN(\n",
    "            circuit=qc,\n",
    "            observables=observable,\n",
    "            input_params=feature_map.parameters,\n",
    "            weight_params=ansatz.parameters,\n",
    "            estimator=estimator,\n",
    "        )\n",
    "\n",
    "        self.q_layer = TorchConnector(\n",
    "            qnn,\n",
    "            \n",
    "            initial_weights=np.random.rand(ansatz.num_parameters),\n",
    "        )\n",
    "        \n",
    "        self.c_layer = nn.Linear(1, 2) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.q_layer(x)\n",
    "        x = self.c_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efbac940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(config_name, n_passive_per_batch, n_active_per_batch, X_pool, y_pool, X_test_tensor, y_test_tensor, initial_indices, initial_model_state):\n",
    "   \n",
    "    \n",
    "    print(f\"\\n--- Iniciando Simulação: {config_name} ({n_passive_per_batch}P + {n_active_per_batch}A) ---\")\n",
    "    \n",
    "    # Criar cópias dos dados\n",
    "    local_X_pool = np.copy(X_pool)\n",
    "    local_y_pool = np.copy(y_pool)\n",
    "    \n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TRAIN)\n",
    "\n",
    "    \n",
    "    labeled_X_pca = [torch.tensor(local_X_pool[i], dtype=torch.float32) for i in initial_indices]\n",
    "    labeled_y = [torch.tensor(local_y_pool[i], dtype=torch.long) for i in initial_indices]\n",
    "    \n",
    "    unlabeled_indices = np.array(list(set(range(len(local_y_pool))) - set(initial_indices)))\n",
    "    \n",
    "    \n",
    "    model = HybridQNN(N_QUBITS, N_LAYERS)\n",
    "    model.load_state_dict(initial_model_state) \n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    \n",
    "    current_accuracy = 0.0\n",
    "    history = [] \n",
    "    \n",
    "    while current_accuracy < TARGET_ACCURACY and len(unlabeled_indices) > 0:\n",
    "        \n",
    "        # 5.1. Avaliar\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        current_accuracy = correct / total\n",
    "        n_labeled = len(labeled_y)\n",
    "        history.append((n_labeled, current_accuracy))\n",
    "        print(f\"[{config_name}] Rótulos: {n_labeled:4d} | Precisão: {current_accuracy:.4f}\")\n",
    "\n",
    "        if current_accuracy >= TARGET_ACCURACY:\n",
    "            break\n",
    "            \n",
    "        \n",
    "        new_labels_pca = []\n",
    "        new_labels_y = []\n",
    "        indices_to_remove = []\n",
    "        \n",
    "        current_unlabeled_indices = np.copy(unlabeled_indices) \n",
    "\n",
    "        \n",
    "        n_to_query_passive = min(n_passive_per_batch, len(current_unlabeled_indices))\n",
    "        if n_to_query_passive > 0:\n",
    "            \n",
    "            passive_indices = np.random.choice(current_unlabeled_indices, n_to_query_passive, replace=False)\n",
    "            \n",
    "            for idx in passive_indices:\n",
    "                new_labels_pca.append(torch.tensor(local_X_pool[idx], dtype=torch.float32))\n",
    "                new_labels_y.append(torch.tensor(local_y_pool[idx], dtype=torch.long))\n",
    "                indices_to_remove.append(idx)\n",
    "            \n",
    "            mask_to_remove_passive = np.isin(current_unlabeled_indices, passive_indices)\n",
    "            current_unlabeled_indices = current_unlabeled_indices[~mask_to_remove_passive]\n",
    "\n",
    "        \n",
    "        n_to_query_active = min(n_active_per_batch, len(current_unlabeled_indices))\n",
    "        if n_to_query_active > 0:\n",
    "            \n",
    "            n_to_check = min(ACTIVE_BATCH_SIZE, len(current_unlabeled_indices))\n",
    "            if n_to_check == 0:\n",
    "                break\n",
    "                \n",
    "            batch_indices_relative = np.random.choice(range(len(current_unlabeled_indices)), n_to_check, replace=False)\n",
    "            batch_indices_absolute = current_unlabeled_indices[batch_indices_relative]\n",
    "            \n",
    "            X_U_batch_pca = torch.tensor(local_X_pool[batch_indices_absolute], dtype=torch.float32)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(X_U_batch_pca)\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "            \n",
    "            uncertainty = torch.abs(probs[:, 0] - probs[:, 1])\n",
    "            most_uncertain_indices_relative = torch.argsort(uncertainty)[:n_to_query_active]\n",
    "            \n",
    "            active_indices_raw = batch_indices_absolute[most_uncertain_indices_relative]\n",
    "            active_indices = np.atleast_1d(active_indices_raw) # Correção do bug anterior\n",
    "\n",
    "            for idx in active_indices:\n",
    "                new_labels_pca.append(torch.tensor(local_X_pool[idx], dtype=torch.float32))\n",
    "                new_labels_y.append(torch.tensor(local_y_pool[idx], dtype=torch.long))\n",
    "                indices_to_remove.append(idx)\n",
    "\n",
    "       \n",
    "        labeled_X_pca.extend(new_labels_pca)\n",
    "        labeled_y.extend(new_labels_y)\n",
    "        \n",
    "        \n",
    "        mask_to_remove_all = np.isin(unlabeled_indices, indices_to_remove)\n",
    "        unlabeled_indices = unlabeled_indices[~mask_to_remove_all]\n",
    "        \n",
    "        \n",
    "        train_dataset = TensorDataset(torch.stack(labeled_X_pca), torch.stack(labeled_y))\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "        \n",
    "        model.train()\n",
    "        for epoch in range(N_FINETUNE_EPOCHS):\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "    print(f\"--- Simulação {config_name} Concluída ---\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd18cf50",
   "metadata": {},
   "source": [
    "# Main Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0b490b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Data processed succecfully. Pool: 10346 samples. Test: 4434 samples.\n",
      "\n",
      "--- A criar o ponto de partida comum (Treino Inicial) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rs/wmb9tlw54_57w8bqd4qxp_zh0000gn/T/ipykernel_2644/228944700.py:16: DeprecationWarning: The class ``qiskit.primitives.estimator.Estimator`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseEstimatorV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Estimator` class is `StatevectorEstimator`.\n",
      "  estimator = Estimator()\n",
      "/var/folders/rs/wmb9tlw54_57w8bqd4qxp_zh0000gn/T/ipykernel_2644/228944700.py:18: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
      "  qnn = EstimatorQNN(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m initial_model(inputs)\n\u001b[1;32m     31\u001b[0m         loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, labels)\n\u001b[0;32m---> 32\u001b[0m         \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     36\u001b[0m initial_model_state \u001b[38;5;241m=\u001b[39m initial_model\u001b[38;5;241m.\u001b[39mstate_dict()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    639\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    640\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    645\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    646\u001b[0m     )\n\u001b[0;32m--> 647\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/graph.py:829\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/function.py:311\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    309\u001b[0m     )\n\u001b[1;32m    310\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/qiskit_machine_learning/connectors/torch_connector.py:229\u001b[0m, in \u001b[0;36m_TorchNNFunction.backward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m    226\u001b[0m     grad_output \u001b[38;5;241m=\u001b[39m grad_output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# evaluate QNN gradient\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m input_grad, weights_grad \u001b[38;5;241m=\u001b[39m \u001b[43mneural_network\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39msparse:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/qiskit_machine_learning/neural_networks/neural_network.py:257\u001b[0m, in \u001b[0;36mNeuralNetwork.backward\u001b[0;34m(self, input_data, weights)\u001b[0m\n\u001b[1;32m    255\u001b[0m input_, shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_input(input_data)\n\u001b[1;32m    256\u001b[0m weights_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_weights(weights)\n\u001b[0;32m--> 257\u001b[0m input_grad, weight_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m input_grad_reshaped, weight_grad_reshaped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_backward_output(\n\u001b[1;32m    260\u001b[0m     input_grad, weight_grad, shape\n\u001b[1;32m    261\u001b[0m )\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m input_grad_reshaped, weight_grad_reshaped\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/qiskit_machine_learning/neural_networks/estimator_qnn.py:364\u001b[0m, in \u001b[0;36mEstimatorQNN._backward\u001b[0;34m(self, input_data, weights)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m QiskitMachineLearningError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimator job failed. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/qiskit/primitives/primitive_job.py:51\u001b[0m, in \u001b[0;36mPrimitiveJob.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResultT:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_submitted()\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:440\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "    X_pool, y_pool, X_test_np, y_test_np = load_and_preprocess_data()\n",
    "    X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test_np, dtype=torch.long)\n",
    "\n",
    "    \n",
    "    print(\"\\n--- A criar o ponto de partida comum (Treino Inicial) ---\")\n",
    "    \n",
    "    \n",
    "    initial_indices = np.random.choice(range(len(y_pool)), N_INITIAL_SAMPLES, replace=False)\n",
    "    \n",
    "    \n",
    "    labeled_X_pca = [torch.tensor(X_pool[i], dtype=torch.float32) for i in initial_indices]\n",
    "    labeled_y = [torch.tensor(y_pool[i], dtype=torch.long) for i in initial_indices]\n",
    "    \n",
    "    train_dataset = TensorDataset(torch.stack(labeled_X_pca), torch.stack(labeled_y))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "    \n",
    "    \n",
    "    initial_model = HybridQNN(N_QUBITS, N_LAYERS)\n",
    "    optimizer = optim.Adam(initial_model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    initial_model.train()\n",
    "    for epoch in range(N_INITIAL_EPOCHS):\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = initial_model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    \n",
    "    initial_model_state = initial_model.state_dict()\n",
    "    print(\"--- Ponto de partida criado. A iniciar as 11 simulações. ---\")\n",
    "    \n",
    "    \n",
    "    configurations = []\n",
    "    for n_active in range(TOTAL_QUERY_BATCH_SIZE + 1): # De 0 a 10\n",
    "        n_passive = TOTAL_QUERY_BATCH_SIZE - n_active\n",
    "        config_name = f\"({n_passive}P + {n_active}A)\"\n",
    "        configurations.append((config_name, n_passive, n_active))\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    print(\"\\nAVISO: As 11 simulações vão começar. Isto pode demorar várias horas.\")\n",
    "    start_time_total = time.time()\n",
    "\n",
    "    for name, n_p, n_a in configurations:\n",
    "        start_time_sim = time.time()\n",
    "        \n",
    "        history = run_simulation(\n",
    "            name, n_p, n_a, \n",
    "            X_pool, y_pool, X_test_tensor, y_test_tensor,\n",
    "            initial_indices, initial_model_state\n",
    "        )\n",
    "        results[name] = history\n",
    "        print(f\"Tempo da simulação {name}: {(time.time() - start_time_sim)/60:.2f} minutos\")\n",
    "\n",
    "    print(f\"\\n--- EXPERIÊNCIA COMPLETA CONCLUÍDA ---\")\n",
    "    print(f\"Tempo total: {(time.time() - start_time_total)/60:.2f} minutos\")\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(14, 9))\n",
    "    \n",
    "    for name, history in results.items():\n",
    "        if history:\n",
    "            x_data, y_data = zip(*history)\n",
    "            plt.plot(x_data, y_data, 'o-', label=name, markersize=4, alpha=0.8)\n",
    "\n",
    "    plt.axhline(y=TARGET_ACCURACY, color='gray', linestyle=':', label=f\"{TARGET_ACCURACY * 100}% Target\")\n",
    "    plt.xlabel(\"Número Total de Rótulos\")\n",
    "    plt.ylabel(\"Precisão no Conjunto de Teste\")\n",
    "    plt.title(\"Comparação de Estratégias de Active Learning (Qiskit+PyTorch)\")\n",
    "    plt.legend(title=\"Estratégia (Passivo + Ativo)\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe66db8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
