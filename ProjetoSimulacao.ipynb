{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc10813f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INICIANDO EXPERIÊNCIA (REPRODUTÍVEL) ---\n",
      "Lotes de 10, Fine-Tuning de 2 épocas.\n",
      "A carregar e pré-processar dados (MNIST)...\n",
      "Dados processados. Pool: 10346 amostras. Teste: 4434 amostras.\n",
      "\n",
      "--- A criar o ponto de partida comum (Treino Inicial) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rs/wmb9tlw54_57w8bqd4qxp_zh0000gn/T/ipykernel_99612/1954512102.py:85: DeprecationWarning: The class ``qiskit.primitives.estimator.Estimator`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseEstimatorV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Estimator` class is `StatevectorEstimator`.\n",
      "  estimator = Estimator()\n",
      "/var/folders/rs/wmb9tlw54_57w8bqd4qxp_zh0000gn/T/ipykernel_99612/1954512102.py:87: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
      "  qnn = EstimatorQNN(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ponto de partida criado. A iniciar as 11 simulações. ---\n",
      "\n",
      "AVISO: As 11 simulações vão começar. Isto pode demorar várias horas.\n",
      "\n",
      "--- Iniciando Simulação: (10P + 0A) (10P + 0A) ---\n",
      "[(10P + 0A)] Rótulos:   20 | Precisão: 0.5365\n",
      "[(10P + 0A)] Rótulos:   30 | Precisão: 0.5505\n",
      "[(10P + 0A)] Rótulos:   40 | Precisão: 0.5589\n",
      "[(10P + 0A)] Rótulos:   50 | Precisão: 0.5659\n",
      "[(10P + 0A)] Rótulos:   60 | Precisão: 0.5893\n",
      "[(10P + 0A)] Rótulos:   70 | Precisão: 0.6155\n",
      "[(10P + 0A)] Rótulos:   80 | Precisão: 0.6520\n",
      "[(10P + 0A)] Rótulos:   90 | Precisão: 0.6788\n",
      "[(10P + 0A)] Rótulos:  100 | Precisão: 0.6764\n",
      "[(10P + 0A)] Rótulos:  110 | Precisão: 0.6953\n",
      "[(10P + 0A)] Rótulos:  120 | Precisão: 0.7102\n",
      "[(10P + 0A)] Rótulos:  130 | Precisão: 0.7185\n",
      "[(10P + 0A)] Rótulos:  140 | Precisão: 0.7341\n",
      "[(10P + 0A)] Rótulos:  150 | Precisão: 0.7447\n",
      "[(10P + 0A)] Rótulos:  160 | Precisão: 0.7650\n",
      "[(10P + 0A)] Rótulos:  170 | Precisão: 0.7641\n",
      "[(10P + 0A)] Rótulos:  180 | Precisão: 0.7749\n",
      "[(10P + 0A)] Rótulos:  190 | Precisão: 0.7747\n",
      "[(10P + 0A)] Rótulos:  200 | Precisão: 0.7747\n",
      "[(10P + 0A)] Rótulos:  210 | Precisão: 0.7794\n",
      "[(10P + 0A)] Rótulos:  220 | Precisão: 0.7833\n",
      "[(10P + 0A)] Rótulos:  230 | Precisão: 0.7871\n",
      "[(10P + 0A)] Rótulos:  240 | Precisão: 0.7839\n",
      "[(10P + 0A)] Rótulos:  250 | Precisão: 0.7885\n",
      "[(10P + 0A)] Rótulos:  260 | Precisão: 0.7873\n",
      "[(10P + 0A)] Rótulos:  270 | Precisão: 0.7848\n",
      "[(10P + 0A)] Rótulos:  280 | Precisão: 0.7907\n",
      "[(10P + 0A)] Rótulos:  290 | Precisão: 0.7921\n",
      "[(10P + 0A)] Rótulos:  300 | Precisão: 0.7988\n",
      "[(10P + 0A)] Rótulos:  310 | Precisão: 0.8002\n",
      "--- Simulação (10P + 0A) Concluída ---\n",
      "Tempo da simulação (10P + 0A): 15.94 minutos\n",
      "\n",
      "--- Iniciando Simulação: (9P + 1A) (9P + 1A) ---\n",
      "[(9P + 1A)] Rótulos:   20 | Precisão: 0.5365\n",
      "[(9P + 1A)] Rótulos:   30 | Precisão: 0.5431\n",
      "[(9P + 1A)] Rótulos:   40 | Precisão: 0.5604\n",
      "[(9P + 1A)] Rótulos:   50 | Precisão: 0.5873\n",
      "[(9P + 1A)] Rótulos:   60 | Precisão: 0.5972\n",
      "[(9P + 1A)] Rótulos:   70 | Precisão: 0.6080\n",
      "[(9P + 1A)] Rótulos:   80 | Precisão: 0.6292\n",
      "[(9P + 1A)] Rótulos:   90 | Precisão: 0.6610\n",
      "[(9P + 1A)] Rótulos:  100 | Precisão: 0.6822\n",
      "[(9P + 1A)] Rótulos:  110 | Precisão: 0.7037\n",
      "[(9P + 1A)] Rótulos:  120 | Precisão: 0.7043\n",
      "[(9P + 1A)] Rótulos:  130 | Precisão: 0.7016\n",
      "[(9P + 1A)] Rótulos:  140 | Precisão: 0.7140\n",
      "[(9P + 1A)] Rótulos:  150 | Precisão: 0.7161\n",
      "[(9P + 1A)] Rótulos:  160 | Precisão: 0.7240\n",
      "[(9P + 1A)] Rótulos:  170 | Precisão: 0.7215\n",
      "[(9P + 1A)] Rótulos:  180 | Precisão: 0.7314\n",
      "[(9P + 1A)] Rótulos:  190 | Precisão: 0.7307\n",
      "[(9P + 1A)] Rótulos:  200 | Precisão: 0.7375\n",
      "[(9P + 1A)] Rótulos:  210 | Precisão: 0.7424\n",
      "[(9P + 1A)] Rótulos:  220 | Precisão: 0.7404\n",
      "[(9P + 1A)] Rótulos:  230 | Precisão: 0.7506\n",
      "[(9P + 1A)] Rótulos:  240 | Precisão: 0.7497\n",
      "[(9P + 1A)] Rótulos:  250 | Precisão: 0.7591\n",
      "[(9P + 1A)] Rótulos:  260 | Precisão: 0.7664\n",
      "[(9P + 1A)] Rótulos:  270 | Precisão: 0.7643\n",
      "[(9P + 1A)] Rótulos:  280 | Precisão: 0.7704\n",
      "[(9P + 1A)] Rótulos:  290 | Precisão: 0.7684\n",
      "[(9P + 1A)] Rótulos:  300 | Precisão: 0.7682\n",
      "[(9P + 1A)] Rótulos:  310 | Precisão: 0.7700\n",
      "[(9P + 1A)] Rótulos:  320 | Precisão: 0.7675\n",
      "[(9P + 1A)] Rótulos:  330 | Precisão: 0.7709\n",
      "[(9P + 1A)] Rótulos:  340 | Precisão: 0.7751\n",
      "[(9P + 1A)] Rótulos:  350 | Precisão: 0.7760\n",
      "[(9P + 1A)] Rótulos:  360 | Precisão: 0.7718\n",
      "[(9P + 1A)] Rótulos:  370 | Precisão: 0.7706\n",
      "[(9P + 1A)] Rótulos:  380 | Precisão: 0.7733\n",
      "[(9P + 1A)] Rótulos:  390 | Precisão: 0.7668\n",
      "[(9P + 1A)] Rótulos:  400 | Precisão: 0.7767\n",
      "[(9P + 1A)] Rótulos:  410 | Precisão: 0.7797\n",
      "[(9P + 1A)] Rótulos:  420 | Precisão: 0.7797\n",
      "[(9P + 1A)] Rótulos:  430 | Precisão: 0.7833\n",
      "[(9P + 1A)] Rótulos:  440 | Precisão: 0.7763\n",
      "[(9P + 1A)] Rótulos:  450 | Precisão: 0.7821\n",
      "[(9P + 1A)] Rótulos:  460 | Precisão: 0.7864\n",
      "[(9P + 1A)] Rótulos:  470 | Precisão: 0.7880\n",
      "[(9P + 1A)] Rótulos:  480 | Precisão: 0.7887\n",
      "[(9P + 1A)] Rótulos:  490 | Precisão: 0.7876\n",
      "[(9P + 1A)] Rótulos:  500 | Precisão: 0.7835\n",
      "[(9P + 1A)] Rótulos:  510 | Precisão: 0.7900\n",
      "[(9P + 1A)] Rótulos:  520 | Precisão: 0.7828\n",
      "[(9P + 1A)] Rótulos:  530 | Precisão: 0.7846\n",
      "[(9P + 1A)] Rótulos:  540 | Precisão: 0.7905\n",
      "[(9P + 1A)] Rótulos:  550 | Precisão: 0.7869\n",
      "[(9P + 1A)] Rótulos:  560 | Precisão: 0.7896\n",
      "[(9P + 1A)] Rótulos:  570 | Precisão: 0.7869\n",
      "[(9P + 1A)] Rótulos:  580 | Precisão: 0.7880\n",
      "[(9P + 1A)] Rótulos:  590 | Precisão: 0.7860\n",
      "[(9P + 1A)] Rótulos:  600 | Precisão: 0.7851\n",
      "[(9P + 1A)] Rótulos:  610 | Precisão: 0.7885\n",
      "[(9P + 1A)] Rótulos:  620 | Precisão: 0.7871\n",
      "[(9P + 1A)] Rótulos:  630 | Precisão: 0.7864\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 295\u001b[0m\n\u001b[1;32m    293\u001b[0m start_time_sim \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Passar os dados E o ponto de partida comum para a função\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mrun_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_model_state\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m results[name] \u001b[38;5;241m=\u001b[39m history\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTempo da simulação \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time_sim)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m minutos\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 232\u001b[0m, in \u001b[0;36mrun_simulation\u001b[0;34m(config_name, n_passive_per_batch, n_active_per_batch, X_pool, y_pool, X_test_tensor, y_test_tensor, initial_indices, initial_model_state)\u001b[0m\n\u001b[1;32m    230\u001b[0m             outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m    231\u001b[0m             loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, labels)\n\u001b[0;32m--> 232\u001b[0m             \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m             optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Simulação \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Concluída ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    639\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    640\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    645\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    646\u001b[0m     )\n\u001b[0;32m--> 647\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/graph.py:829\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/function.py:311\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    309\u001b[0m     )\n\u001b[1;32m    310\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/qiskit_machine_learning/connectors/torch_connector.py:229\u001b[0m, in \u001b[0;36m_TorchNNFunction.backward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m    226\u001b[0m     grad_output \u001b[38;5;241m=\u001b[39m grad_output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# evaluate QNN gradient\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m input_grad, weights_grad \u001b[38;5;241m=\u001b[39m \u001b[43mneural_network\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39msparse:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/qiskit_machine_learning/neural_networks/neural_network.py:257\u001b[0m, in \u001b[0;36mNeuralNetwork.backward\u001b[0;34m(self, input_data, weights)\u001b[0m\n\u001b[1;32m    255\u001b[0m input_, shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_input(input_data)\n\u001b[1;32m    256\u001b[0m weights_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_weights(weights)\n\u001b[0;32m--> 257\u001b[0m input_grad, weight_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m input_grad_reshaped, weight_grad_reshaped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_backward_output(\n\u001b[1;32m    260\u001b[0m     input_grad, weight_grad, shape\n\u001b[1;32m    261\u001b[0m )\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m input_grad_reshaped, weight_grad_reshaped\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/qiskit_machine_learning/neural_networks/estimator_qnn.py:364\u001b[0m, in \u001b[0;36mEstimatorQNN._backward\u001b[0;34m(self, input_data, weights)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m QiskitMachineLearningError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimator job failed. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/qiskit/primitives/primitive_job.py:51\u001b[0m, in \u001b[0;36mPrimitiveJob.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResultT:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_submitted()\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:440\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.primitives import Estimator\n",
    "from qiskit.circuit.library import ZFeatureMap, EfficientSU2\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "\n",
    "# --- 1. Definição dos Parâmetros Globais ---\n",
    "N_QUBITS = 4\n",
    "N_LAYERS = 3\n",
    "TARGET_ACCURACY = 0.80\n",
    "RANDOM_SEED = 42\n",
    "# IMPORTANTE: Definir as seeds globais AQUI e SÓ AQUI\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# Parâmetros da Simulação\n",
    "DIGITS_TO_CLASSIFY = [0, 1]\n",
    "N_INITIAL_SAMPLES = 20\n",
    "TOTAL_QUERY_BATCH_SIZE = 10 # O seu \"de 10 em 10 rótulos\"\n",
    "ACTIVE_BATCH_SIZE = 200     # Em quantas amostras procurar os mais difíceis\n",
    "BATCH_SIZE_TRAIN = 10\n",
    "\n",
    "# Parâmetros de Treino (Rápidos)\n",
    "LEARNING_RATE = 0.01\n",
    "N_INITIAL_EPOCHS = 50       # Treino inicial (lento, 1x por simulação)\n",
    "N_FINETUNE_EPOCHS = 2       # Fine-tuning (rápido, 1x por loop)\n",
    "\n",
    "print(f\"--- INICIANDO EXPERIÊNCIA (REPRODUTÍVEL) ---\")\n",
    "print(f\"Lotes de {TOTAL_QUERY_BATCH_SIZE}, Fine-Tuning de {N_FINETUNE_EPOCHS} épocas.\")\n",
    "\n",
    "\n",
    "# --- 2. Carregamento e Pré-processamento dos Dados ---\n",
    "def load_and_preprocess_data():\n",
    "    \"\"\"Carrega MNIST, filtra, aplica PCA e divide os dados.\"\"\"\n",
    "    print(\"A carregar e pré-processar dados (MNIST)...\")\n",
    "    X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "    y = y.astype(int)\n",
    "\n",
    "    mask = np.isin(y, DIGITS_TO_CLASSIFY)\n",
    "    X_filtered = X[mask]\n",
    "    y_filtered = y[mask]\n",
    "    y_mapped = np.where(y_filtered == DIGITS_TO_CLASSIFY[0], 0, 1)\n",
    "\n",
    "    X_scaled = X_filtered / 255.0 \n",
    "    pca = PCA(n_components=N_QUBITS)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    X_pool, X_test, y_pool, y_test = train_test_split(\n",
    "        X_pca, y_mapped, \n",
    "        test_size=0.3, random_state=RANDOM_SEED, stratify=y_mapped\n",
    "    )\n",
    "    \n",
    "    print(f\"Dados processados. Pool: {len(y_pool)} amostras. Teste: {len(y_test)} amostras.\")\n",
    "    return X_pool, y_pool, X_test, y_test\n",
    "\n",
    "\n",
    "# --- 3. Definição do Modelo Híbrido (PyTorch+Qiskit) ---\n",
    "class HybridQNN(nn.Module):\n",
    "    \"\"\"Modelo Híbrido: Camada Quântica + Camada Clássica.\"\"\"\n",
    "    def __init__(self, n_qubits, n_layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        feature_map = ZFeatureMap(n_qubits)\n",
    "        ansatz = EfficientSU2(n_qubits, reps=n_layers)\n",
    "        \n",
    "        qc = QuantumCircuit(n_qubits)\n",
    "        qc.compose(feature_map, inplace=True)\n",
    "        qc.compose(ansatz, inplace=True)\n",
    "        \n",
    "        pauli_string = \"I\" * (n_qubits - 1) + \"Z\" \n",
    "        observable = SparsePauliOp(pauli_string)\n",
    "        \n",
    "        estimator = Estimator()\n",
    "\n",
    "        qnn = EstimatorQNN(\n",
    "            circuit=qc,\n",
    "            observables=observable,\n",
    "            input_params=feature_map.parameters,\n",
    "            weight_params=ansatz.parameters,\n",
    "            estimator=estimator,\n",
    "        )\n",
    "\n",
    "        self.q_layer = TorchConnector(\n",
    "            qnn,\n",
    "            # Os pesos iniciais são aleatórios, mas controlados pela seed global\n",
    "            initial_weights=np.random.rand(ansatz.num_parameters),\n",
    "        )\n",
    "        \n",
    "        self.c_layer = nn.Linear(1, 2) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.q_layer(x)\n",
    "        x = self.c_layer(x)\n",
    "        return x\n",
    "\n",
    "# --- 4. FUNÇÃO DE SIMULAÇÃO PRINCIPAL (Não-interativa) ---\n",
    "def run_simulation(config_name, n_passive_per_batch, n_active_per_batch, X_pool, y_pool, X_test_tensor, y_test_tensor, initial_indices, initial_model_state):\n",
    "    \"\"\"\n",
    "    Executa uma simulação completa para uma dada configuração.\n",
    "    USA OS MESMOS 20 RÓTULOS INICIAIS E O MESMO MODELO INICIAL.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n--- Iniciando Simulação: {config_name} ({n_passive_per_batch}P + {n_active_per_batch}A) ---\")\n",
    "    \n",
    "    # Criar cópias dos dados\n",
    "    local_X_pool = np.copy(X_pool)\n",
    "    local_y_pool = np.copy(y_pool)\n",
    "    \n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TRAIN)\n",
    "\n",
    "    # --- Setup Inicial (CONTROLADO) ---\n",
    "    # Usar os 20 rótulos iniciais que foram passados como argumento\n",
    "    labeled_X_pca = [torch.tensor(local_X_pool[i], dtype=torch.float32) for i in initial_indices]\n",
    "    labeled_y = [torch.tensor(local_y_pool[i], dtype=torch.long) for i in initial_indices]\n",
    "    \n",
    "    unlabeled_indices = np.array(list(set(range(len(local_y_pool))) - set(initial_indices)))\n",
    "    \n",
    "    # --- Carregar o Modelo Inicial (CONTROLADO) ---\n",
    "    # Garantir que todos os \"corredores\" começam com o mesmo cérebro\n",
    "    model = HybridQNN(N_QUBITS, N_LAYERS)\n",
    "    model.load_state_dict(initial_model_state) # Carregar os pesos\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # --- Loop de Simulação ---\n",
    "    current_accuracy = 0.0\n",
    "    history = [] # Para guardar (n_labels, accuracy)\n",
    "    \n",
    "    while current_accuracy < TARGET_ACCURACY and len(unlabeled_indices) > 0:\n",
    "        \n",
    "        # 5.1. Avaliar\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        current_accuracy = correct / total\n",
    "        n_labeled = len(labeled_y)\n",
    "        history.append((n_labeled, current_accuracy))\n",
    "        print(f\"[{config_name}] Rótulos: {n_labeled:4d} | Precisão: {current_accuracy:.4f}\")\n",
    "\n",
    "        if current_accuracy >= TARGET_ACCURACY:\n",
    "            break\n",
    "            \n",
    "        # Listas temporárias para o novo lote\n",
    "        new_labels_pca = []\n",
    "        new_labels_y = []\n",
    "        indices_to_remove = []\n",
    "        \n",
    "        current_unlabeled_indices = np.copy(unlabeled_indices) \n",
    "\n",
    "        # 5.2. FASE PASSIVA (Automática)\n",
    "        n_to_query_passive = min(n_passive_per_batch, len(current_unlabeled_indices))\n",
    "        if n_to_query_passive > 0:\n",
    "            # As escolhas aleatórias SÃO controladas pela seed global (RANDOM_SEED)\n",
    "            passive_indices = np.random.choice(current_unlabeled_indices, n_to_query_passive, replace=False)\n",
    "            \n",
    "            for idx in passive_indices:\n",
    "                new_labels_pca.append(torch.tensor(local_X_pool[idx], dtype=torch.float32))\n",
    "                new_labels_y.append(torch.tensor(local_y_pool[idx], dtype=torch.long))\n",
    "                indices_to_remove.append(idx)\n",
    "            \n",
    "            mask_to_remove_passive = np.isin(current_unlabeled_indices, passive_indices)\n",
    "            current_unlabeled_indices = current_unlabeled_indices[~mask_to_remove_passive]\n",
    "\n",
    "        # 5.3. FASE ATIVA (Simulada)\n",
    "        n_to_query_active = min(n_active_per_batch, len(current_unlabeled_indices))\n",
    "        if n_to_query_active > 0:\n",
    "            \n",
    "            n_to_check = min(ACTIVE_BATCH_SIZE, len(current_unlabeled_indices))\n",
    "            if n_to_check == 0:\n",
    "                break\n",
    "                \n",
    "            batch_indices_relative = np.random.choice(range(len(current_unlabeled_indices)), n_to_check, replace=False)\n",
    "            batch_indices_absolute = current_unlabeled_indices[batch_indices_relative]\n",
    "            \n",
    "            X_U_batch_pca = torch.tensor(local_X_pool[batch_indices_absolute], dtype=torch.float32)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(X_U_batch_pca)\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "            \n",
    "            uncertainty = torch.abs(probs[:, 0] - probs[:, 1])\n",
    "            most_uncertain_indices_relative = torch.argsort(uncertainty)[:n_to_query_active]\n",
    "            \n",
    "            active_indices_raw = batch_indices_absolute[most_uncertain_indices_relative]\n",
    "            active_indices = np.atleast_1d(active_indices_raw) # Correção do bug anterior\n",
    "\n",
    "            for idx in active_indices:\n",
    "                new_labels_pca.append(torch.tensor(local_X_pool[idx], dtype=torch.float32))\n",
    "                new_labels_y.append(torch.tensor(local_y_pool[idx], dtype=torch.long))\n",
    "                indices_to_remove.append(idx)\n",
    "\n",
    "        # 5.4. Atualizar o pool de treino\n",
    "        labeled_X_pca.extend(new_labels_pca)\n",
    "        labeled_y.extend(new_labels_y)\n",
    "        \n",
    "        # 5.5. Remover todos os índices do pool principal\n",
    "        mask_to_remove_all = np.isin(unlabeled_indices, indices_to_remove)\n",
    "        unlabeled_indices = unlabeled_indices[~mask_to_remove_all]\n",
    "        \n",
    "        # 5.6. Fine-Tuning (SÓ UMA VEZ)\n",
    "        # O shuffle=True é aleatório, mas controlado pela seed global (RANDOM_SEED)\n",
    "        train_dataset = TensorDataset(torch.stack(labeled_X_pca), torch.stack(labeled_y))\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "        \n",
    "        model.train()\n",
    "        for epoch in range(N_FINETUNE_EPOCHS):\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "    print(f\"--- Simulação {config_name} Concluída ---\")\n",
    "    return history\n",
    "\n",
    "\n",
    "# --- 5. Execução (O SCRIPT PRINCIPAL) ---\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Carregar os dados UMA SÓ VEZ\n",
    "    X_pool, y_pool, X_test_np, y_test_np = load_and_preprocess_data()\n",
    "    X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test_np, dtype=torch.long)\n",
    "\n",
    "    # --- PASSO NOVO: Criar o Ponto de Partida Comum ---\n",
    "    print(\"\\n--- A criar o ponto de partida comum (Treino Inicial) ---\")\n",
    "    \n",
    "    # 1. Escolher os 20 rótulos iniciais (controlado pela RANDOM_SEED)\n",
    "    initial_indices = np.random.choice(range(len(y_pool)), N_INITIAL_SAMPLES, replace=False)\n",
    "    \n",
    "    # 2. Criar os dados de treino iniciais\n",
    "    labeled_X_pca = [torch.tensor(X_pool[i], dtype=torch.float32) for i in initial_indices]\n",
    "    labeled_y = [torch.tensor(y_pool[i], dtype=torch.long) for i in initial_indices]\n",
    "    \n",
    "    train_dataset = TensorDataset(torch.stack(labeled_X_pca), torch.stack(labeled_y))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "    \n",
    "    # 3. Criar e treinar o modelo inicial\n",
    "    initial_model = HybridQNN(N_QUBITS, N_LAYERS)\n",
    "    optimizer = optim.Adam(initial_model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    initial_model.train()\n",
    "    for epoch in range(N_INITIAL_EPOCHS):\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = initial_model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # 4. Guardar os \"pesos\" deste modelo treinado\n",
    "    initial_model_state = initial_model.state_dict()\n",
    "    print(\"--- Ponto de partida criado. A iniciar as 11 simulações. ---\")\n",
    "    \n",
    "    # ---\n",
    "    \n",
    "    # --- Defina as suas experiências aqui ---\n",
    "    configurations = []\n",
    "    for n_active in range(TOTAL_QUERY_BATCH_SIZE + 1): # De 0 a 10\n",
    "        n_passive = TOTAL_QUERY_BATCH_SIZE - n_active\n",
    "        config_name = f\"({n_passive}P + {n_active}A)\"\n",
    "        configurations.append((config_name, n_passive, n_active))\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    print(\"\\nAVISO: As 11 simulações vão começar. Isto pode demorar várias horas.\")\n",
    "    start_time_total = time.time()\n",
    "\n",
    "    for name, n_p, n_a in configurations:\n",
    "        start_time_sim = time.time()\n",
    "        # Passar os dados E o ponto de partida comum para a função\n",
    "        history = run_simulation(\n",
    "            name, n_p, n_a, \n",
    "            X_pool, y_pool, X_test_tensor, y_test_tensor,\n",
    "            initial_indices, initial_model_state\n",
    "        )\n",
    "        results[name] = history\n",
    "        print(f\"Tempo da simulação {name}: {(time.time() - start_time_sim)/60:.2f} minutos\")\n",
    "\n",
    "    print(f\"\\n--- EXPERIÊNCIA COMPLETA CONCLUÍDA ---\")\n",
    "    print(f\"Tempo total: {(time.time() - start_time_total)/60:.2f} minutos\")\n",
    "\n",
    "    # --- Plotar o Gráfico Final ---\n",
    "    plt.figure(figsize=(14, 9))\n",
    "    \n",
    "    for name, history in results.items():\n",
    "        if history:\n",
    "            x_data, y_data = zip(*history)\n",
    "            plt.plot(x_data, y_data, 'o-', label=name, markersize=4, alpha=0.8)\n",
    "\n",
    "    plt.axhline(y=TARGET_ACCURACY, color='gray', linestyle=':', label=f\"{TARGET_ACCURACY * 100}% Target\")\n",
    "    plt.xlabel(\"Número Total de Rótulos\")\n",
    "    plt.ylabel(\"Precisão no Conjunto de Teste\")\n",
    "    plt.title(\"Comparação de Estratégias de Active Learning (Qiskit+PyTorch)\")\n",
    "    plt.legend(title=\"Estratégia (Passivo + Ativo)\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe66db8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
